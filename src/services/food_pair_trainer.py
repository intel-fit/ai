# src/services/food_pair_trainer.py
import os, json, math, itertools, time
from collections import Counter, defaultdict
import pandas as pd

DATA_DIR = os.path.join("src", "data")
LOG_PATH = os.path.join(DATA_DIR, "meal_logs.jsonl")  # ÌïòÎ£®Î≥Ñ Ï∂îÏ≤ú Í≤∞Í≥º Î°úÍ∑∏
PAIR_OUT_PARQUET = os.path.join(DATA_DIR, "food_pair_scores.parquet")
PAIR_OUT_JSON = os.path.join(DATA_DIR, "food_pair_scores.json")
FOOD_DB_PATH = os.path.join(DATA_DIR, "cleaned_food_db_final.xlsx")  # ‚úÖ Ï†ïÏ†úÎêú DB Í∏∞Î∞ò ÌïÑÌÑ∞ÎßÅ


def _norm_pair(a: str, b: str):
    a, b = str(a), str(b)
    return (a, b) if a <= b else (b, a)


# ---------------------------------------------------------
# 1Ô∏è‚É£ Î°úÍ∑∏ Î°úÎìú
# ---------------------------------------------------------
def load_logs(path=LOG_PATH):
    """meal_logs.jsonl Î°úÎìú (1Ï§Ñ = 1ÏùºÏπò ÏãùÎã® Î°úÍ∑∏)"""
    if not os.path.exists(path):
        print(f"‚ö†Ô∏è No logs found at {path}")
        return []
    rows = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            try:
                rows.append(json.loads(line))
            except:
                pass
    print(f"üìò Loaded {len(rows)} daily logs")
    return rows


# ---------------------------------------------------------
# 2Ô∏è‚É£ ÌïòÎ£® ÏãùÎã®ÏóêÏÑú ÏùåÏãùÏåç Ï∂îÏ∂ú
# ---------------------------------------------------------
def extract_pairs_from_daily_plan(daily_plan: dict):
    """Ìïú Ïùº(day)Ïùò Í∞Å ÎÅºÎãàÏóêÏÑú ÏïÑÏù¥ÌÖú food_nameÏùÑ ÎΩëÏïÑ ÌéòÏñ¥/Îã®Ïùº Ï∂úÌòÑ Ïπ¥Ïö¥Ìä∏."""
    single = Counter()
    pair = Counter()
    meals = daily_plan.get("meals", [])
    for meal in meals:
        names = []
        for it in meal.get("items", []):
            n = it.get("food_name")
            if not n:
                continue
            names.append(n)

        # Îã®Ïùº Ï∂úÌòÑÏàò
        for n in set(names):
            single[n] += 1

        # ÏùåÏãùÏåç Ï°∞Ìï©
        for a, b in itertools.combinations(sorted(set(names)), 2):
            pair[(a, b)] += 1
    return single, pair


# ---------------------------------------------------------
# 3Ô∏è‚É£ Î©îÏù∏ ÌïôÏäµ Ìï®Ïàò
# ---------------------------------------------------------
def train_from_logs():
    logs = load_logs()
    # ‚öôÔ∏è Î°úÍ∑∏ ÏóÜÏùÑ Îïå ÏÉòÌîå ÏÉùÏÑ± (ÌÖåÏä§Ìä∏Ïö©)
    if not logs:
        print("‚ö†Ô∏è No logs found. Generating small synthetic sample for testing...")
        sample_daily = {
            "meals": [
                {"items": [{"food_name": "ÌòÑÎØ∏Î∞•"}, {"food_name": "Îã≠Í∞ÄÏä¥ÏÇ¥"}, {"food_name": "ÏÉêÎü¨Îìú"}]},
                {"items": [{"food_name": "Ïû°Í≥°Î∞•"}, {"food_name": "ÎëêÎ∂Ä"}, {"food_name": "ÎÇòÎ¨º"}]},
                {"items": [{"food_name": "Í≥†Íµ¨Îßà"}, {"food_name": "Í≥ÑÎûÄ"}, {"food_name": "Î∏åÎ°úÏΩúÎ¶¨"}]},
            ]
        }
        logs = [{"daily_plan": sample_daily} for _ in range(10)]

    # ‚úÖ Ïú†Ìö® ÏùåÏãù Î™©Î°ù Î°úÎìú (Ï†ïÏ†úÎêú DB Í∏∞Î∞ò ÌïÑÌÑ∞ÎßÅ)
    valid_foods = set()
    if os.path.exists(FOOD_DB_PATH):
        db = pd.read_excel(FOOD_DB_PATH)
        valid_foods = set(db["food_name"].astype(str).tolist())
        print(f"‚úÖ Loaded {len(valid_foods)} valid food names from DB")

    single = Counter()
    pair = Counter()
    N_meals = 0

    # ---- Î™®Îì† Î°úÍ∑∏ ÏàúÌöå ----
    for row in logs:
        daily = row.get("daily_plan") or row.get("plan") or {}
        s, p = extract_pairs_from_daily_plan(daily)
        single.update(s)
        pair.update(p)
        N_meals += len(daily.get("meals", []))

    # ---- ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ ----
    min_single = 2  # 2Ìöå Ïù¥ÏÉÅ Îì±Ïû•Ìïú ÏùåÏãùÎßå
    min_pair = 2    # 2Ìöå Ïù¥ÏÉÅ Îì±Ïû•Ìïú ÌéòÏñ¥Îßå
    single = Counter({k: v for k, v in single.items() if v >= min_single})
    pair = Counter({k: v for k, v in pair.items() if v >= min_pair and k[0] in single and k[1] in single})

    # ---- Ïú†Ìö® ÏùåÏãùÎßå ÎÇ®Í∏∞Í∏∞ ----
    if valid_foods:
        pair = Counter({(a, b): c for (a, b), c in pair.items() if a in valid_foods and b in valid_foods})
        single = Counter({k: v for k, v in single.items() if k in valid_foods})

    print(f"üìä Training pairs: {len(pair)}, singles: {len(single)}, meals logged: {N_meals}")

    # ---- PMI / Lift Í≥ÑÏÇ∞ ----
    k = 1.0
    vocab = set(single.keys())
    N = max(1, N_meals)
    records = []

    for (a, b), c_ab in pair.items():
        c_a = single.get(a, 0)
        c_b = single.get(b, 0)
        p_a = (c_a + k) / (N + k * len(vocab))
        p_b = (c_b + k) / (N + k * len(vocab))
        p_ab = (c_ab + k) / (N + k * len(vocab))

        pmi = math.log(max(1e-12, p_ab / (p_a * p_b)))
        lift = p_ab / (p_a * p_b)
        pmi_sig = 1 / (1 + math.exp(-pmi))
        support = c_ab
        score = pmi_sig * (1 - math.exp(-support / 5))
        records.append({
            "food_a": a, "food_b": b,
            "count_ab": c_ab, "count_a": c_a, "count_b": c_b,
            "pmi": pmi, "lift": lift, "score": score
        })

    # ---- Ï†ÄÏû• ----
    df = pd.DataFrame(records).sort_values("score", ascending=False)
    os.makedirs(DATA_DIR, exist_ok=True)
    df.to_parquet(PAIR_OUT_PARQUET, index=False)

    # ---- JSON (ÏñëÎ∞©Ìñ• Îß§Ìïë, ÏïàÏ†Ñ ÌïÑÌÑ∞ Ìè¨Ìï®) ----
    top = df[df["score"] > 0].copy()
    pair_map = defaultdict(list)
    for _, r in top.iterrows():
        if not isinstance(r["food_a"], str) or not isinstance(r["food_b"], str):
            continue
        pair_map[r["food_a"]].append([r["food_b"], float(r["score"])])
        pair_map[r["food_b"]].append([r["food_a"], float(r["score"])])

    with open(PAIR_OUT_JSON, "w", encoding="utf-8") as f:
        json.dump({"updated": int(time.time()), "pairs": pair_map}, f, ensure_ascii=False)

    print(f"‚úÖ Pair training done. meals={N_meals:,}, pairs={len(df):,}, saved ‚Üí {PAIR_OUT_JSON}")
    return df


if __name__ == "__main__":
    train_from_logs()
